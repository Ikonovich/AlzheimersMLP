import math
from random import random, choice
from typing import Callable

from Core import vectorDot, vectorAdd, vectorMul, sigmoid, relu


# Generates a new random neuron weight
def generateWeight() -> float:
    return random() - 0.5


class Neuron:
    ACTIVATION_MAP = {"relu": relu, "sigmoid": sigmoid, None: None}

    def __init__(self,
                 network,
                 layerId: int,
                 neuronId: str,
                 input_size: int,
                 activation: str = None,
                 bias_mod: float = 0):
        self.network = network
        self.neuronId = neuronId
        self.layerId = layerId
        # self.weights = matrix(rows=input_size, cols=output_size, fill=lambda: random() - 0.5)
        self.weights = [generateWeight() for i in range(input_size)]
        self.bias = 0.0

        self.input = [0 for i in range(input_size)]
        self.activation = Neuron.ACTIVATION_MAP[activation]
        self.activation_str = activation
        self.output = 0.0
        self.output_prime = 0.0

        self.bias_mod = bias_mod

        self.loss = 0

    def forward(self):
        neuronIds = self.network.idToInput[self.neuronId]
        total = 0
        for i in range(len(neuronIds)):
            neuron = self.network.idToNeuron[neuronIds[i]]
            self.input[i] = neuron.output
            total += neuron.output * self.weights[i]
        total += self.bias * self.bias_mod

        # Apply activation, if necessary, and get the derivative.
        if self.activation is not None:
            self.output, self.output_prime = self.activation(total)
        else:
            self.output = total
            self.output_prime = 1

    def backward(self):
        # Accumulate our loss
        outputIds = self.network.idToOutput[self.neuronId]
        loss = list()
        for i in range(len(outputIds)):
            outputId = outputIds[i]
            index = self.network.idToInput[outputId].index(self.neuronId)
            loss.append(self.network.idToNeuron[outputId].loss[index])

        totalLoss = sum(loss)

        # Calculate our delta
        delta = totalLoss * self.output_prime
        self.loss = list()
        for i in range(len(self.weights)):
            self.loss.append(self.weights[i] * delta)

        # Update the weights
        weightedLoss = vectorMul(self.input, totalLoss)
        weightShift = vectorMul(weightedLoss, self.output_prime)
        self.weights = vectorAdd(self.weights, weightShift)
        self.bias += totalLoss * self.bias_mod

    @staticmethod
    def toDict(neuron, inputIds: list[str], outputIds: list[str]) -> dict:
        # Returns the neuron in a serializable format.
        neuronDict = dict()
        neuronDict["type"] = "Neuron"
        neuronDict["neuronId"] = neuron.neuronId
        neuronDict["layerId"] = neuron.layerId
        neuronDict["weights"] = neuron.weights
        neuronDict["biasMod"] = neuron.bias_mod
        neuronDict["bias"] = neuron.bias
        neuronDict["activation"] = neuron.activation_str

        neuronDict["inputIds"] = inputIds
        neuronDict["outputIds"] = outputIds

        return neuronDict

    @staticmethod
    def fromDict(neuronDict: dict, network=None) -> "Neuron":
        # Creates a neuron object from a dictionary generated by toDict().
        neuronId = neuronDict["neuronId"]
        layerId = neuronDict["layerId"]
        weights = neuronDict["weights"]
        bias_mod = neuronDict["biasMod"]
        bias = neuronDict["bias"]
        activation_str = neuronDict["activation"]

        inputIds = neuronDict["inputIds"]
        outputIds = neuronDict["outputIds"]
        neuron = Neuron(network=network,
                        layerId=layerId,
                        neuronId=neuronId,
                        input_size=len(weights),
                        activation=activation_str,
                        bias_mod=bias_mod)

        neuron.bias = bias
        neuron.weights = weights
        return neuron